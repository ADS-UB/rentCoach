{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rentdata = pd.read_csv('version2.csv')\n",
    "y=rentdata['price'].values\n",
    "rentdata=rentdata.drop('price',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the feature we want to predict (price), ant split our training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=rentdata.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=44)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4556L, 10L)\n",
      "(507L, 10L)\n",
      "(5063L, 10L)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a vector (x,x^2,x^3,....,x^i)\n",
    "def extend(x,n):\n",
    "    x_extend=x\n",
    "    for i in range(1,n): x_extend=np.c_[x_extend,x**(i+1)]\n",
    "    return x_extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Root mean squared error\n",
    "def rmse(y,yhat):\n",
    "    dif=y-yhat\n",
    "    N=len(y)\n",
    "    return sqrt((1./N)*np.dot(dif.T,dif))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CMAX=20\n",
    "Err=np.zeros((CMAX,3,2))\n",
    "reg_meth=['Linear Regression','Ridge regressor','Gradient Boosting Regressor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Linear Regressor\n",
    "lreg = LinearRegression(fit_intercept=True,normalize=False)\n",
    "for i in range(CMAX):\n",
    "    lreg.fit(extend(X_train,i+1),y_train)\n",
    "    yhat_in=lreg.predict(extend(X_train,i+1))\n",
    "    Err[i,0,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=lreg.predict(extend(X_test,i+1))\n",
    "    Err[i,0,1]=rmse(y_test,yhat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ridge Regressor\n",
    "rid = Ridge()\n",
    "for i in range(CMAX):\n",
    "    rid.fit(extend(X_train,i+1), y_train)\n",
    "    yhat_in=rid.predict(extend(X_train,i+1))\n",
    "    Err[i,1,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=rid.predict(extend(X_test,i+1))\n",
    "    Err[i,1,1]=rmse(y_test,yhat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Regressor\n",
    "gbr=GradientBoostingRegressor()\n",
    "for i in range(CMAX):\n",
    "    gbr.fit(extend(X_train,i+1), y_train)\n",
    "    yhat_in=gbr.predict(extend(X_train,i+1))\n",
    "    Err[i,2,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=gbr.predict(extend(X_test,i+1))\n",
    "    Err[i,2,1]=rmse(y_test,yhat_out)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98.6486884813 105.634328219\n",
      "[0 2]\n",
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "Ein_min=Err[:,:,0].min()\n",
    "Eout_min=Err[:,:,1].min()\n",
    "idx_inmin=np.asarray([np.where(Err[:,:,0]==Ein_min)[0][0],np.where(Err[:,:,0]==Ein_min)[1][0]])\n",
    "idx_outmin=np.asarray([np.where(Err[:,:,1]==Eout_min)[0][0],np.where(Err[:,:,1]==Eout_min)[1][0]])\n",
    "print Ein_min,Eout_min\n",
    "print idx_inmin\n",
    "print idx_outmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \t Linear Regressor \t         Ridge Regressor \t  Gradient Boosting Regressor\n",
      "C    \t  Ein         Eout       \t  Ein           Eout   \t          Ein          Eout\n",
      "1    568.916323952   567.407849445   568.916414517   567.389616799   98.6486884813   105.634328219\n",
      "2    425.977908286   420.218280316   425.979276046   420.066813244   100.063896487   108.402748709\n",
      "3    360.70088846   350.916178347   360.704833338   350.839263686   100.063896487   109.82077164\n",
      "4    329.989766793   339.85298328   329.993895263   339.581907107   100.063896487   109.309703189\n",
      "5    316.723963331   723.893010014   316.730738711   725.391895793   100.063896487   110.088709574\n",
      "6    311.863561288   468.458005844   311.870519752   463.933663467   100.063896487   109.227941209\n",
      "7    305.798835924   1563.73731854   305.806135144   1591.32720929   100.063896487   111.359591184\n",
      "8    298.352976307   13733.3022337   298.359426651   13551.0575175   100.063896487   109.471396064\n",
      "9    295.973744482   24829.3947007   295.981987005   24005.055477   100.063896487   109.74431407\n",
      "10    294.009282541   80144.3368265   294.036244819   66985.9198636   100.063896487   108.501016639\n",
      "11    292.37337408   3529337.32426   292.444436186   2200595.03492   100.063896487   110.147924486\n",
      "12    290.820216789   11094526.2641   290.931038161   7420703.82227   100.063896487   110.339898214\n",
      "13    289.548324439   57646955.4616   289.655521937   55316907.6634   100.063896487   110.337547988\n",
      "14    289.671175025   194377161.621   289.603875392   193717141.656   100.063896487   109.847998825\n",
      "15    288.639511511   2474278040.71   288.799353389   859550206.622   100.063896487   110.335275747\n",
      "16    296.854399958   9436983695.49   350.821709181   30887203167.8   100.063896487   107.557128567\n",
      "17    804.790055477   32184250729.2   1145.34303453   323444533078.0   100.063896487   111.55717283\n",
      "18    3978.42443083   69666055985.2   2047.3572869   2.34857957613e+12   100.063896487   107.042072055\n",
      "19    1763.43928384   664677144705.0   1512.8714993   2.8138500801e+12   100.063896487   110.87269234\n",
      "20    980.237054035   277076381328.0   1684.28284427   56770868769.7   100.063896487   107.779198588\n",
      "\n",
      "\n",
      "The minimum Ein is 98.6486884813 for Gradient Boosting Regressor ,complexity 1\n",
      "\n",
      "\n",
      "The minimum Eout is 105.634328219 for Gradient Boosting Regressor ,complexity 1\n"
     ]
    }
   ],
   "source": [
    "print '     \\t Linear Regressor \\t         Ridge Regressor \\t  Gradient Boosting Regressor'\n",
    "print 'C    \\t  Ein         Eout       \\t  Ein           Eout   \\t          Ein          Eout'\n",
    "for i in range(CMAX):\n",
    "    print  i+1,'  ',Err[i,0,0],' ',Err[i,0,1],' ',Err[i,1,0],' ',Err[i,1,1],' ',Err[i,2,0],' ',Err[i,2,1]\n",
    "print '\\n\\nThe minimum Ein is',Ein_min,'for',reg_meth[idx_inmin[1]],',complexity',idx_inmin[0]+1\n",
    "print '\\n\\nThe minimum Eout is',Eout_min,'for',reg_meth[idx_outmin[1]],',complexity',idx_outmin[0]+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein= 97.5461841012\n"
     ]
    }
   ],
   "source": [
    "X_scaled=scaler.fit_transform(X)\n",
    "if idx_outmin[1]==0: freg = LinearRegression()\n",
    "if idx_outmin[1]==1: freg = Ridge() \n",
    "if idx_outmin[1]==2: freg = GradientBoostingRegressor()\n",
    "i=idx_outmin[0]\n",
    "freg.fit(extend(X_scaled,i+1),y)\n",
    "yhat_in=freg.predict(extend(X_scaled,i+1))\n",
    "Ein=rmse(y,yhat_in)\n",
    "#yhat_out=freg.predict()\n",
    "\n",
    "print 'Ein=',Ein#,'\\t Eout=',Eout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
