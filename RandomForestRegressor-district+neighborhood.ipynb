{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "data = pd.read_csv('version4_district+neighborhood.csv')\n",
    "\n",
    "#data= data.drop(['Unnamed: 0', 'newdevelopment'], axis=1)\n",
    "\n",
    "#preu_park_noinclos\n",
    "#preu_park_noinclos=((data['hasParkingSpace']!=data['isParkingSpaceIncludedInPrice']).astype(float))\n",
    "#data=pd.concat((data,preu_park_noinclos),axis=1)\n",
    "#data.drop(\"isParkingSpaceIncludedInPrice\",axis=1)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data['price'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove outliers\n",
    "\n",
    "\n",
    "per=np.percentile(np.array(data['price']), [2.5, 90])\n",
    "data=data[data['price']>per[0]]\n",
    "data=data[data['price']<per[1]]\n",
    "\n",
    "data['price'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y =data['price']\n",
    "X = data.drop(['price'], axis=1)\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Linear regression\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "#tuned_parameters = [{'bootstrap': [True, False],'criterion': [\"gini\", \"entropy\"],'n_estimators': [10, 50, 100, 200, 500]}]\n",
    "tuned_parameters = [{'normalize' : [True,False]}]\n",
    "#scores = ['precision', 'recall']\n",
    "\n",
    "#scores = ['precision']\n",
    "#scores = ['f1']\n",
    "\n",
    "#print \"Tuning hyper-parameters for %s\" % score\n",
    "print\n",
    "clf = GridSearchCV(LinearRegression(fit_intercept=True), tuned_parameters, cv=10, scoring='neg_mean_absolute_error')\n",
    "clf.fit(X_train, y_train)\n",
    "print \"Best parameters set found on training set:\"\n",
    "print\n",
    "print clf.best_params_ \n",
    "print\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#y_true=y_true.astype('float64')\n",
    "#print \"Confusion matrix:\"\n",
    "#print\n",
    "#print confusion_matrix(y_true, y_pred)\n",
    "#print\n",
    "#print \"Classification report:\"\n",
    "#print classification_report(y_true, y_pred)\n",
    "print \"Mean Absolute Error:\"\n",
    "print\n",
    "print metrics.mean_absolute_error(y_true, y_pred)\n",
    "print\n",
    "print \"The model is trained on the training set. The scores are computed on the testing set.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random Forest Regressor\n",
    "#n_estimators estimate\n",
    "\n",
    "start_time = time.time()\n",
    "# Set the parameters by cross-validation\n",
    "#tuned_parameters = [{'bootstrap': [True, False],'criterion': [\"gini\", \"entropy\"],'n_estimators': [10, 50, 100, 200, 500]}]\n",
    "tuned_parameters = [{'bootstrap': [True, False],\n",
    "                     'n_estimators': [200, 500, 600, 750], 'max_features': [\"auto\", \"sqrt\", \"log2\"]}]\n",
    "#scores = ['precision', 'recall']\n",
    "\n",
    "#scores = ['precision']\n",
    "#scores = ['f1']\n",
    "\n",
    "#print \"Tuning hyper-parameters for %s\" % score\n",
    "print\n",
    "clf = GridSearchCV(RandomForestRegressor(n_estimators=10, random_state=44, n_jobs=-1), tuned_parameters, cv=10, \n",
    "                   scoring='neg_mean_absolute_error')\n",
    "clf.fit(X_train, y_train)\n",
    "print \"Best parameters set found on training set:\"\n",
    "print\n",
    "print clf.best_params_ \n",
    "print\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#y_true=y_true.astype('float64')\n",
    "#print \"Confusion matrix:\"\n",
    "#print\n",
    "#print confusion_matrix(y_true, y_pred)\n",
    "#print\n",
    "#print \"Classification report:\"\n",
    "#print classification_report(y_true, y_pred)\n",
    "print \"Mean Absolute Error:\"\n",
    "print\n",
    "print metrics.mean_absolute_error(y_true, y_pred)\n",
    "print\n",
    "print \"The model is trained on the training set. The scores are computed on the testing set.\"\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random Forest Regressor\n",
    "#n_estimators estimate\n",
    "\n",
    "start_time = time.time()\n",
    "# Set the parameters by cross-validation\n",
    "#tuned_parameters = [{'bootstrap': [True, False],'criterion': [\"gini\", \"entropy\"],'n_estimators': [10, 50, 100, 200, 500]}]\n",
    "tuned_parameters = [{'bootstrap': [True, False],\n",
    "                     'n_estimators': [450, 500, 550], 'max_features': [\"auto\", \"sqrt\", \"log2\"]}]\n",
    "#scores = ['precision', 'recall']\n",
    "\n",
    "#scores = ['precision']\n",
    "#scores = ['f1']\n",
    "\n",
    "#print \"Tuning hyper-parameters for %s\" % score\n",
    "print\n",
    "clf = GridSearchCV(RandomForestRegressor(n_estimators=10, random_state=44, n_jobs=-1), tuned_parameters, cv=10, \n",
    "                   scoring='neg_mean_absolute_error')\n",
    "clf.fit(X_train, y_train)\n",
    "print \"Best parameters set found on training set:\"\n",
    "print\n",
    "print clf.best_params_ \n",
    "print\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#y_true=y_true.astype('float64')\n",
    "#print \"Confusion matrix:\"\n",
    "#print\n",
    "#print confusion_matrix(y_true, y_pred)\n",
    "#print\n",
    "#print \"Classification report:\"\n",
    "#print classification_report(y_true, y_pred)\n",
    "print \"Mean Absolute Error:\"\n",
    "print\n",
    "print metrics.mean_absolute_error(y_true, y_pred)\n",
    "print\n",
    "print \"The model is trained on the training set. The scores are computed on the testing set.\"\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#score with best parameters\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestRegressor(n_estimators=550, max_features='sqrt', bootstrap=False, random_state=44, n_jobs=-1)\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='neg_mean_absolute_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores=np.abs(scores)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "#Tenemos que normalizar y??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training set:\n",
      "\n",
      "{'max_features': 'auto', 'loss': 'huber', 'learning_rate': 0.2, 'n_estimators': 600, 'max_depth': 2}\n",
      "\n",
      "Mean Absolute Error:\n",
      "\n",
      "270.651042323\n",
      "\n",
      "The model is trained on the training set. The scores are computed on the testing set.\n",
      "--- 359.494624138 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#Gradient Boosting Regressor\n",
    "#n_estimators estimate\n",
    "\n",
    "start_time = time.time()\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'n_estimators':[500, 600], \n",
    "                     'learning_rate':[0.1,0.2],'max_depth':[1,2], \n",
    "                     'loss':['ls', 'lad', 'huber'], 'max_features':[\"auto\", \"sqrt\", \"log2\"]}]\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingRegressor(criterion='friedman_mse', random_state=44), tuned_parameters, cv=10, \n",
    "                   scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print \"Best parameters set found on training set:\"\n",
    "print\n",
    "print clf.best_params_ \n",
    "print\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#y_true=y_true.astype('float64')\n",
    "#print \"Confusion matrix:\"\n",
    "#print\n",
    "#print confusion_matrix(y_true, y_pred)\n",
    "#print\n",
    "#print \"Classification report:\"\n",
    "#print classification_report(y_true, y_pred)\n",
    "print \"Mean Absolute Error:\"\n",
    "print\n",
    "print metrics.mean_absolute_error(y_true, y_pred)\n",
    "print\n",
    "print \"The model is trained on the training set. The scores are computed on the testing set.\"\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#score with best parameters\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = GradientBoostingRegressor(n_estimators=600,learning_rate=0.2, max_depth=2, loss='huber',\n",
    "                                max_features='auto', random_state=44)\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='neg_mean_absolute_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 218.34881224  274.48439974  287.74649595  267.58977667  294.73432257\n",
      "  295.29030965  264.67901067  309.04735089  297.93994701  250.27092521]\n",
      "276.01313506\n",
      "25.7320742385\n"
     ]
    }
   ],
   "source": [
    "scores=np.abs(scores)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
