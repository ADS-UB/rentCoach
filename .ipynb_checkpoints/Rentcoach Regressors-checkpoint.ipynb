{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rentdata = pd.read_csv('version2.csv')\n",
    "y=rentdata['price'].values\n",
    "rentdata=rentdata.drop(['price','priceByArea'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the feature we want to predict (price), ant split our training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=rentdata.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=44)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4556L, 9L)\n",
      "(507L, 9L)\n",
      "[[  0.00000000e+00   2.00000000e+00   1.75000000e+02 ...,   4.14009887e+01\n",
      "    2.13407280e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   3.00000000e+00   6.80000000e+01 ...,   4.13729812e+01\n",
      "    2.17312780e+00   1.00000000e+00]\n",
      " [  2.00000000e+00   0.00000000e+00   1.02000000e+02 ...,   4.14514736e+01\n",
      "    2.25330310e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  5.45300000e+03   1.00000000e+00   5.20000000e+01 ...,   4.14132696e+01\n",
      "    2.18136290e+00   1.00000000e+00]\n",
      " [  5.45400000e+03   2.00000000e+00   1.00000000e+02 ...,   4.14706535e+01\n",
      "    2.04266240e+00   1.00000000e+00]\n",
      " [  5.45500000e+03   1.00000000e+00   9.00000000e+01 ...,   4.13955441e+01\n",
      "    2.17670030e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a vector (x,x^2,x^3,....,x^i)\n",
    "def extend(x,n):\n",
    "    x_extend=x\n",
    "    for i in range(1,n): x_extend=np.c_[x_extend,x**(i+1)]\n",
    "    return x_extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Root mean squared error\n",
    "def rmse(y,yhat):\n",
    "    dif=y-yhat\n",
    "    N=len(y)\n",
    "    return sqrt((1./N)*np.dot(dif.T,dif))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CMAX=20\n",
    "Err=np.zeros((CMAX,4,2))\n",
    "reg_meth=['Linear Regression','Ridge regressor','SVR','Gradient Boosting Regressor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Linear Regressor\n",
    "lreg = LinearRegression(fit_intercept=True,normalize=False)\n",
    "for i in range(CMAX):\n",
    "    lreg.fit(extend(X_train,i+1),y_train)\n",
    "    yhat_in=lreg.predict(extend(X_train,i+1))\n",
    "    Err[i,0,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=lreg.predict(extend(X_test,i+1))\n",
    "    Err[i,0,1]=rmse(y_test,yhat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ridge Regressor\n",
    "rid = Ridge()\n",
    "for i in range(CMAX):\n",
    "    rid.fit(extend(X_train,i+1), y_train)\n",
    "    yhat_in=rid.predict(extend(X_train,i+1))\n",
    "    Err[i,1,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=rid.predict(extend(X_test,i+1))\n",
    "    Err[i,1,1]=rmse(y_test,yhat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Support Vector Regressor\n",
    "svr = SVR(kernel='rbf')\n",
    "for i in range(CMAX):\n",
    "    svr.fit(extend(X_train,i+1), y_train)\n",
    "    yhat_in=rid.predict(extend(X_train,i+1))\n",
    "    Err[i,1,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=svr.predict(extend(X_test,i+1))\n",
    "    Err[i,1,1]=rmse(y_test,yhat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Regressor\n",
    "gbr=GradientBoostingRegressor()\n",
    "for i in range(CMAX):\n",
    "    gbr.fit(extend(X_train,i+1), y_train)\n",
    "    yhat_in=gbr.predict(extend(X_train,i+1))\n",
    "    Err[i,2,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=gbr.predict(extend(X_test,i+1))\n",
    "    Err[i,2,1]=rmse(y_test,yhat_out)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538.929622672 573.282237592\n",
      "[1 2]\n",
      "[3 2]\n"
     ]
    }
   ],
   "source": [
    "Ein_min=Err[:,:,0].min()\n",
    "Eout_min=Err[:,:,1].min()\n",
    "idx_inmin=np.asarray([np.where(Err[:,:,0]==Ein_min)[0][0],np.where(Err[:,:,0]==Ein_min)[1][0]])\n",
    "idx_outmin=np.asarray([np.where(Err[:,:,1]==Eout_min)[0][0],np.where(Err[:,:,1]==Eout_min)[1][0]])\n",
    "print Ein_min,Eout_min\n",
    "print idx_inmin\n",
    "print idx_outmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \t Linear Regressor \t         Ridge Regressor \t  Gradient Boosting Regressor\n",
      "C    \t  Ein         Eout       \t  Ein           Eout   \t          Ein          Eout\n",
      "1    739.489752774   725.80298137   739.489782665   725.787717276   544.353721682   584.362730291\n",
      "2    686.417998378   669.764357581   686.418115657   669.729475745   538.929622672   573.771608534\n",
      "3    683.677644774   666.289161199   683.677850395   666.262336945   538.929622672   574.209619962\n",
      "4    677.404538731   710.491631316   677.401951955   710.004440092   538.929622672   573.282237592\n",
      "5    664.651245921   843.269666621   664.651640528   842.122212944   538.929622672   574.450063879\n",
      "6    661.287064706   680.528834069   661.288359292   677.315965602   538.929622672   574.499450109\n",
      "7    655.905830578   4340.85069838   655.919930018   4338.24239987   538.929622672   574.79360137\n",
      "8    650.304742381   16735.0882292   650.320311421   16390.5507876   538.929622672   574.867138699\n",
      "9    649.573702394   14163.5127697   649.582480459   12356.3007878   538.929622672   575.124100576\n",
      "10    644.337610919   26235.9070168   644.366210707   9102.36363316   538.929622672   573.547767869\n",
      "11    639.59273724   1379014.70892   639.66566025   622163.736339   538.929622672   573.902522838\n",
      "12    639.402596049   5312948.30744   639.485669838   3016233.83192   538.929622672   574.015544274\n",
      "13    635.154146844   29754218.1621   635.523268154   29244636.7862   538.929622672   575.416769611\n",
      "14    633.116124531   297690333.633   634.048723621   292999100.554   538.929622672   573.983212972\n",
      "15    634.6567081   4877633423.58   633.482688498   3384956356.09   538.929622672   573.974940217\n",
      "16    631.838620047   30208387960.7   633.282040175   44619301880.9   538.929622672   574.985076408\n",
      "17    677.528137385   259129171857.0   660.607811027   320167644733.0   538.929622672   574.203078213\n",
      "18    704.729771142   333452140784.0   1090.61853574   1.56631689889e+13   538.929622672   575.179975303\n",
      "19    890.131933176   2.11077147647e+12   4145.96540041   1.66899248605e+13   538.929622672   573.651498697\n",
      "20    949.507086094   309116348408.0   1191.17409144   5.51102908999e+13   538.929622672   576.010429711\n",
      "\n",
      "\n",
      "The minimum Ein is 538.929622672 for Gradient Boosting Regressor ,complexity 2\n",
      "\n",
      "\n",
      "The minimum Eout is 573.282237592 for Gradient Boosting Regressor ,complexity 4\n"
     ]
    }
   ],
   "source": [
    "print '     \\t Linear Regressor \\t         Ridge Regressor \\t  Gradient Boosting Regressor'\n",
    "print 'C    \\t  Ein         Eout       \\t  Ein           Eout   \\t          Ein          Eout'\n",
    "for i in range(CMAX):\n",
    "    print  i+1,'  ',Err[i,0,0],' ',Err[i,0,1],' ',Err[i,1,0],' ',Err[i,1,1],' ',Err[i,2,0],' ',Err[i,2,1]\n",
    "print '\\n\\nThe minimum Ein is',Ein_min,'for',reg_meth[idx_inmin[1]],',complexity',idx_inmin[0]+1\n",
    "print '\\n\\nThe minimum Eout is',Eout_min,'for',reg_meth[idx_outmin[1]],',complexity',idx_outmin[0]+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein= 535.52809371\n"
     ]
    }
   ],
   "source": [
    "X_scaled=scaler.fit_transform(X)\n",
    "if idx_outmin[1]==0: freg = LinearRegression()\n",
    "if idx_outmin[1]==1: freg = Ridge() \n",
    "if idx_outmin[1]==2: freg = GradientBoostingRegressor()\n",
    "i=idx_outmin[0]\n",
    "freg.fit(extend(X_scaled,i+1),y)\n",
    "yhat_in=freg.predict(extend(X_scaled,i+1))\n",
    "Ein=rmse(y,yhat_in)\n",
    "#yhat_out=freg.predict()\n",
    "\n",
    "print 'Ein=',Ein#,'\\t Eout=',Eout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
