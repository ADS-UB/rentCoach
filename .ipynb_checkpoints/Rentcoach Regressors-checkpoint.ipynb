{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rentdata = pd.read_csv('version2.csv')\n",
    "y=rentdata['price'].values\n",
    "rentdata=rentdata.drop('price',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the feature we want to predict (price), ant split our training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=rentdata.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=44)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4556L, 10L)\n",
      "(507L, 10L)\n",
      "(5063L, 10L)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a vector (x,x^2,x^3,....,x^i)\n",
    "def extend(x,n):\n",
    "    x_extend=x\n",
    "    for i in range(1,n): x_extend=np.c_[x_extend,x**(i+1)]\n",
    "    return x_extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Root mean squared error\n",
    "def rmse(y,yhat):\n",
    "    dif=y-yhat\n",
    "    N=len(y)\n",
    "    return sqrt((1./N)*np.dot(dif.T,dif))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CMAX=20\n",
    "Err=np.zeros((CMAX,3,2))\n",
    "reg_meth=['Linear Regression','Ridge regressor','Gradient Boosting Regressor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Linear Regressor\n",
    "lreg = LinearRegression(fit_intercept=True,normalize=False)\n",
    "for i in range(CMAX):\n",
    "    lreg.fit(extend(X_train,i+1),y_train)\n",
    "    yhat_in=lreg.predict(extend(X_train,i+1))\n",
    "    Err[i,0,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=lreg.predict(extend(X_test,i+1))\n",
    "    Err[i,0,1]=rmse(y_test,yhat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ridge Regressor\n",
    "rid = Ridge()\n",
    "for i in range(CMAX):\n",
    "    rid.fit(extend(X_train,i+1), y_train)\n",
    "    yhat_in=rid.predict(extend(X_train,i+1))\n",
    "    Err[i,1,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=rid.predict(extend(X_test,i+1))\n",
    "    Err[i,1,1]=rmse(y_test,yhat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Regressor\n",
    "gbr=GradientBoostingRegressor()\n",
    "for i in range(CMAX):\n",
    "    gbr.fit(extend(X_train,i+1), y_train)\n",
    "    yhat_in=gbr.predict(extend(X_train,i+1))\n",
    "    Err[i,2,0]=rmse(y_train,yhat_in)\n",
    "    yhat_out=gbr.predict(extend(X_test,i+1))\n",
    "    Err[i,2,1]=rmse(y_test,yhat_out)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512.812922103 554.039633927\n",
      "[1 2]\n",
      "[18  2]\n"
     ]
    }
   ],
   "source": [
    "Ein_min=Err[:,:,0].min()\n",
    "Eout_min=Err[:,:,1].min()\n",
    "idx_inmin=np.asarray([np.where(Err[:,:,0]==Ein_min)[0][0],np.where(Err[:,:,0]==Ein_min)[1][0]])\n",
    "idx_outmin=np.asarray([np.where(Err[:,:,1]==Eout_min)[0][0],np.where(Err[:,:,1]==Eout_min)[1][0]])\n",
    "print Ein_min,Eout_min\n",
    "print idx_inmin\n",
    "print idx_outmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \t Linear Regressor \t         Ridge Regressor \t  Gradient Boosting Regressor\n",
      "C    \t  Ein         Eout       \t  Ein           Eout   \t          Ein          Eout\n",
      "1    680.360057684   669.169963561   680.36009126   669.168829747   518.558389212   567.105470159\n",
      "2    645.424511207   654.759276172   645.424638878   654.726222714   512.812922103   554.807259202\n",
      "3    636.276532368   652.924434236   636.276624399   652.876626015   512.812922103   555.859404149\n",
      "4    625.290903678   647.852235094   625.291110769   647.776496262   512.812922103   554.760074394\n",
      "5    615.429624402   639.276825281   615.429907715   639.173128785   512.812922103   554.748513749\n",
      "6    612.494222208   635.295210111   612.494679992   635.217159562   512.812922103   554.815549649\n",
      "7    610.900827439   636.058252076   610.90152058   635.973539576   512.812922103   554.815549649\n",
      "8    609.193954682   632.5076305   609.195535281   632.452456184   512.812922103   554.726595352\n",
      "9    608.212576781   634.612994953   608.214639135   634.499548311   512.812922103   554.815549649\n",
      "10    607.397222011   635.577383257   607.454899315   635.029421294   512.812922103   554.815549649\n",
      "11    604.403752866   632.660120685   604.42417073   632.887936369   512.812922103   554.807259202\n",
      "12    604.762119267   635.527549645   603.922536811   633.428707952   512.812922103   554.807259202\n",
      "13    615.417712096   646.846344554   609.144733694   638.518644069   512.812922103   554.760074394\n",
      "14    727.783118774   756.139835222   609.967867746   630.249153612   512.812922103   554.815549649\n",
      "15    825.411999369   814.334252147   776.257949521   766.942512475   512.812922103   554.815549649\n",
      "16    917.948586155   877.333649964   1378.60915916   1153.92782513   512.812922103   554.756805075\n",
      "17    860.162768479   857.013142023   848.114491312   845.885195396   512.812922103   554.815549649\n",
      "18    885.800448661   873.842829327   920.834187442   871.999920334   512.812922103   555.867678905\n",
      "19    918.778481872   915.114492508   886.31088589   864.354618699   512.812922103   554.039633927\n",
      "20    1700.00607816   1072.82860676   1423.14614651   1043.84217037   512.812922103   554.345952098\n",
      "\n",
      "\n",
      "The minimum Ein is 512.812922103 for Gradient Boosting Regressor ,complexity 2\n",
      "\n",
      "\n",
      "The minimum Eout is 554.039633927 for Gradient Boosting Regressor ,complexity 19\n"
     ]
    }
   ],
   "source": [
    "print '     \\t Linear Regressor \\t         Ridge Regressor \\t  Gradient Boosting Regressor'\n",
    "print 'C    \\t  Ein         Eout       \\t  Ein           Eout   \\t          Ein          Eout'\n",
    "for i in range(CMAX):\n",
    "    print  i+1,'  ',Err[i,0,0],' ',Err[i,0,1],' ',Err[i,1,0],' ',Err[i,1,1],' ',Err[i,2,0],' ',Err[i,2,1]\n",
    "print '\\n\\nThe minimum Ein is',Ein_min,'for',reg_meth[idx_inmin[1]],',complexity',idx_inmin[0]+1\n",
    "print '\\n\\nThe minimum Eout is',Eout_min,'for',reg_meth[idx_outmin[1]],',complexity',idx_outmin[0]+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein= 514.485720852\n"
     ]
    }
   ],
   "source": [
    "X_scaled=scaler.fit_transform(X)\n",
    "if idx_outmin[1]==0: freg = LinearRegression()\n",
    "if idx_outmin[1]==1: freg = Ridge() \n",
    "if idx_outmin[1]==2: freg = GradientBoostingRegressor()\n",
    "i=idx_outmin[0]\n",
    "freg.fit(extend(X_scaled,i+1),y)\n",
    "yhat_in=freg.predict(extend(X_scaled,i+1))\n",
    "Ein=rmse(y,yhat_in)\n",
    "#yhat_out=freg.predict()\n",
    "\n",
    "print 'Ein=',Ein#,'\\t Eout=',Eout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
